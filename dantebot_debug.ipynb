{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "data = open('data/dante.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "# dict eg. {'a':1} for all chars\n",
    "vocab = dict(zip(chars, range(len(chars))))\n",
    "# apply dict.get to all data\n",
    "# all chars of the text are \"encoded\" in numbers\n",
    "tensor = np.array(list(map(vocab.get,data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "seq_len = 10\n",
    "rnn_size = 10\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_batches = int(tensor.size/(batch_size*seq_len))\n",
    "tensor = tensor[:num_batches*batch_size*seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata = tensor\n",
    "ydata = np.copy(tensor)\n",
    "len(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ydata[:-1] = xdata[1:]\n",
    "ydata[-1] = xdata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is a list where each entry is a 10x10 matrix\n",
    "# each row is an encoded seq of words of size 10\n",
    "x_batches = np.split(xdata.reshape(batch_size, -1), num_batches,1)\n",
    "y_batches = np.split(xdata.reshape(batch_size, -1), num_batches,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = x_batches[0]\n",
    "y_data = y_batches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I/O\n",
    "x_model = tf.placeholder(tf.int32, [batch_size, seq_len])\n",
    "y_model = tf.placeholder(tf.int32, [batch_size, seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cells\n",
    "cell = rnn_cell.LSTMCell(rnn_size, state_is_tuple=True, activation= tf.nn.elu)\n",
    "multi_cell = rnn_cell.MultiRNNCell([cell]*num_layers, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init state cell\n",
    "init = multi_cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# W and bias\n",
    "softmax_w = tf.get_variable('softmax_w', [rnn_size, vocab_size])\n",
    "softmax_b = tf.get_variable('softmax_b', [vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word embedding the output is a list of vector of size seq_len\n",
    "embedding = tf.get_variable('embedding', [vocab_size, rnn_size])\n",
    "input_lookup = tf.nn.embedding_lookup(embedding, x_model)\n",
    "inputs = tf.split(1, seq_len, input_lookup)\n",
    "inputs_list = [tf.squeeze(input_, [1]) for input_ in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decoder from tf example\n",
    "output_seq, last_state = seq2seq.rnn_decoder(inputs_list, init, multi_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = tf.reshape(tf.concat(1, output_seq), [-1, rnn_size])\n",
    "logits = tf.matmul(output, softmax_w)+softmax_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# probs is a prob matrix where each entry is the prob of the correct guess\n",
    "probs = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute loss across the seq_len\n",
    "cross_seq = seq2seq.sequence_loss_by_example([logits],\n",
    "                                         [tf.reshape(y_model,[-1])],\n",
    "                                        [tf.ones([batch_size*seq_len])],\n",
    "                                        vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# averaging over the seq_len\n",
    "cost = tf.reduce_sum(cross_seq) / batch_size / seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model 2 uses dnn \n",
    "output_dnn, end_state = tf.nn.dynamic_rnn(multi_cell, input_lookup, initial_state=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dnn = tf.reshape(output_dnn, [-1, batch_size])\n",
    "log_dnn = tf.matmul(output_dnn, softmax_w) + softmax_b\n",
    "prob_dnn = tf.nn.softmax(log_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_reshaped = tf.reshape(y_model,[-1])\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(prob_dnn, y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_loss = tf.reduce_mean(cross_entropy)\n",
    "cost = tf.reduce_sum(cross_seq) / batch_size / seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "state = sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed = {x_model:x_data, y_model:y_data}\n",
    "for i, (c,h) in enumerate(init):\n",
    "    feed[c] = state[i].c\n",
    "    feed[h] = state[i].h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0488653"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_dnn, loss_dnn = sess.run([cross_entropy, total_loss], feed)\n",
    "cr_seq, loss_seq = sess.run([cross_seq, cost], feed)\n",
    "loss_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3963375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "\n",
    "\t\twith tf.name_scope('summaries'):\n",
    "\t\t\tmean = tf.reduce_mean(var)\n",
    "\t\t\ttf.summary.scalar('mean',var)\n",
    "\n",
    "\t\t\twith tf.name_scope('sd'):\n",
    "\t\t\t\tsd = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "\t\t\t\ttf.summary.scalar('sd', sd)\n",
    "\t\t\t\ttf.summary.scalar('max',tf.reduce_max(var))\n",
    "\t\t\t\ttf.summary.scalar('min',tf.reduce_min(var))\n",
    "\t\t\t\ttf.summary.histogram('histogram',var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_summaries(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.variable_summaries>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
